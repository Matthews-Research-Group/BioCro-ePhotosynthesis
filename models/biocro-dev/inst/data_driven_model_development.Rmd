Efficient uncertainty reduction through data-driven model development
=====================================================================

Authors: David LeBauer, Michael Dietze, Deepak Jaiswal, Rob Kooper, Steve Long, Dan Wang

Introduction 
------------
  Ecological forecasts have diverse sources of uncertainty, and the value of an ecological forecast is directly related to its accuracy and precision.
  We apply process control and integration testing to target model development toward more precise ecological forecasts.
  Benchmarks and skill metrics are used to quantify changes in the uncertainty of our ecological predictions that result from changes in parameterization and model structure.
  This approach reduces the uncertainty associated with the addition of new features to a model by testing that the software implementation of a model is consistent with our conceptual model.
  Furthermore, the use of fixed benchmark data and software version control makes it easier to isolate the source of changes in model performance.
  This form of integration testing facilitates iterative development by providing immediate feedback on the effects of each step in model development.

  As an example of this approach, we will review our experience adding the capacity to simulate tree growth to an existing model of C4 grasses (BioCro).
  In this example, we illustrate the use of uncertainty as an empirical metric to guide efficient and effective research.

also see: https://epad.dataone.org/archive/content/20111115-ilamb.txt

Results
-------

  The use of model skill metrics during model development allowed us to iteratively evaluate and reassess the focus of our model development efforts.
  Model skill improved substantially with the introduction of well established models of tree physiology: the Farquhar model of C3 photosynthesis, addition of a woody biomass pool, and deciduous phenology.
  Subsequent refinements were less effective at improving model skill.

  The relationship between effort and model uncertainty provided an empirical foundation on which to iteratively identify and reassess the focus of our model development efforts.
  The progressive improvments in skill helped us identify how well the incorporation of specific mechanisms improved model skill.
  At the same time, we could confirm our predictions of which model components are most important, and identify targets for further research.

```{r }

knitr::opts_chunk$set(echo=FALSE, eval=FALSE,comment = FALSE, warning = FALSE, echo = FALSE)
```

### map of observed data

```{r}
sites <- read.csv("inst/extdata/validation_sites.csv")
world <- map_data("world")
ggplot() + 
  geom_polygon(data=world, aes(x=long, y=lat, group = group), colour="grey", fill="white" ) + 
    geom_point(data = sites, aes(x = lon, y = lat), color = 'red') 

+  scale_size(range = c(8,12)) 
```

```{r}
pred <- list()
for(version in c("60", "70", "75", "81", "92")) {
  load(paste0("C:/Users/dlebauer/R-dev/biocro/inst/extdata/v0", version, ".RData"))  
  pred[[version]] <- compareStem$Predicted
}

pred.df <- as.data.frame(pred)
colnames(pred.df) <- gsub("X", "V0.", colnames(pred.df))
results <- cbind(observed = compareStem$Observed, study = compareStem$Irrigated, pred.df)

obs <- results[33:74,c("study", "observed")]
obs <- cbind(obs, year = rep(1:6,7), rotation = rep(1:3, 14), site = rep(1:6, each = 7))

ggplot(data = obs, aes(year, observed)) + 
  geom_point(aes(by = site))

results.long <- data.frame(study = rep(results$study, 5),
                           observed = rep(results$observed, 5),
                           modeled = unlist(results[3:7]),
                           version = rep(names(results[3:7]), each = length(results[[1]])))
                           
```



```{r fig.width=7, fig.height=6}
library(plotrix)
taylor.diagram(results$observed, results$V0.75, normalize = TRUE, sd.arcs=TRUE)
taylor.diagram(results$observed, results$V0.60, normalize = TRUE, add = TRUE)
taylor.diagram(results$observed, results$V0.70, normalize = TRUE, add = TRUE)
taylor.diagram(results$observed, results$V0.81, normalize = TRUE, add = TRUE)
taylor.diagram(results$observed, results$V0.92, normalize = TRUE, add = TRUE)

mean <- sapply(results[,3:7], mean)

## sd.r: reference (observed)
sd.r <- sd(results$observed)
## sd.f: modeled
sd.f <- sapply(results[,3:7], sd)




R <- sapply(results[,3:7], function(x) cor(x, results$observed, use = "pairwise"))

## calculate E' from eqn 2 in Taylor 2001
fn <- results[,3:7]
fbar <- colMeans(fn)
rn <- results$observed
rbar <- mean(rn)

# E <- list()
# for(i in 1:5){
#   E[i] <- (sum(((fn[,i] - fbar[i]) - (rn - rbar))^2)/length(rn)) ^ 0.5
#   }

## alt. method, second column of Taylor 2001 p 7184:
E <- sqrt(sd.f^2 + sd.r^2 - 2 * sd.f * sd.r * R)

bias <- fbar - rbar
plot(1:5, sd.f/sd.r, type = "l")
par(mfrow = c(4,1), mar = c(1,4,1,1))
plot(1:5, sd.f, ylim = c(0,25), type = "l")
abline(h = sd.r)
plot(1:5, R, ylim = c(0,1), type = "l")
abline(h = 1)
plot(1:5, E, ylim = c(0,20), type = "l")
abline(h = 0)
plot(1:5, bias, ylim = c(0,20), type = "l")
abline(h = 0)
### calculate points to plot on taylor diagram
x <- (sd.f/sd.r) * R
y <- (sd.f/sd.r) * sin(acos(R))

point.order <- order(names(x))

x <- x[point.order]
y <- y[point.order]
R <- R[point.order]
sd.f <- sd.f[point.order]/sd.r

lines(x, y)

ang <- c(0, -10, 10, -150, 110)
sapply(2:length(x), function(xind) text(x[xind], y[xind], 
                                          labels = c("", rep(">  ", 4)), 
                                        srt = ang[xind]))

versions <- c("", "add C3", "perenating stem", "growth respiration", "leaf senescence")
text(x + c(0, 0.08, 0.22, 0.26, -0.24), y - c(0, 0.05, 0, 0, 0), labels = versions)

```


### Summary of changes 

```{r}
```


### Test changes

```{r}
## stepwise
V0.70 <- t.test(results$V0.60, results$V0.70, paired = TRUE)
V0.75 <- t.test(results$V0.70, results$V0.75, paired = TRUE)
V0.81 <- t.test(results$V0.75, results$V0.81, paired = TRUE)
V0.92 <- t.test(results$V0.81, results$V0.92, paired = TRUE)
### Overall
V0.6_V0.92 <- t.test(results$V0.60, results$V0.92, paired = TRUE)

result.table <- data.frame(version = names(x), 
                      description = c("start", "added C3", "perenating stem", "growth respiration", "leaf senescence"), 
                      sd = round(sd.f, 2), RMSE = round(R, 2), P = round(c(NA, V0.70$p.value, V0.75$p.value, V0.81$p.value, V0.92$p.value), 2))
library(pander)
panderOptions('table.split.table', Inf)
```

```{r results='asis'}
pandoc.table(result.table[,-1], style = 'rmarkdown')
```

```{r fig.width=7, fig.height=6}
results.long <- cbind(results.long, id = rep(1:nrow(results), 5), v = rep(1:5 /5 ,each = 74))
results.long 
offset <- (as.numeric(as.factor(results.long$version))-2.5)/5
library(ggplot2)
ggplot(data = results.long, aes(observed + offset, modeled)) + 
  geom_line(aes(group = id, color = version, size = v/3)) +
  geom_point(aes(color = version, size = v)) + theme_bw() + scale_colour_grey(start = 0.85, end = 0.15) +
    geom_line(aes(x = c(0,80), y = c(0,80)), linetype = 2) +
  xlab("Observed") + ylab("Modeled") + ggtitle("Observed vs. Predicted Willow Yield")

ggplot(data = results.long[results.long$version == "V0.91",], aes(observed, modeled)) + 
  geom_point() + theme_bw() + scale_colour_grey(start = 0.85, end = 0.15) +
    geom_line(aes(x = c(0,80), y = c(0,80)), size = 0.5, linetype = 2) +
  xlab("Observed") + ylab("Modeled") + ggtitle("Observed vs. Predicted Willow Yield")
```
